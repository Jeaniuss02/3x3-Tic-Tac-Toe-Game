{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bru7jT8VLX6F"
      },
      "source": [
        "## **Tasks**\n",
        "* In this coursework, you will implement Value Iteration, Policy Iteration that plan/learn to play 3x3 Tic-Tac-Toe game. You will test your agents against other rule-based agents that are provided. You can also play against all the agents including your own agents to test them.\n",
        "* A general framework for the game and agents is provided. Run each code cell below in order, when you see a <>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBek_YuBQzED"
      },
      "source": [
        "### Part 0: Environment: packages, constants, basic code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGtHyRUXVZwm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# Constants for the game\n",
        "EMPTY = 0\n",
        "PLAYER_X = 1\n",
        "PLAYER_O = -1\n",
        "GAME_ROW, GAME_COL = 3, 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8tNVHrqQzTK"
      },
      "source": [
        "#### 0.1: The ***Game*** class:\n",
        "\n",
        "play(): simulate one game\n",
        "\n",
        "*show_board* indicate whether the states are printed during play"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTW_W_wlQtve"
      },
      "outputs": [],
      "source": [
        "class Game:\n",
        "    \"\"\"\n",
        "    Define the tictactoe game. The function and variable names should be self explained.\n",
        "\n",
        "    @author: chenxy\n",
        "    \"\"\"\n",
        "    def __init__(self, player_x, player_o, show_board=False):\n",
        "        self.board = np.zeros((GAME_ROW, GAME_COL), dtype=int)\n",
        "        self.player_x = player_x\n",
        "        self.player_o = player_o\n",
        "        self.current_player = self.player_x\n",
        "        self.winner = None\n",
        "        self.show_board = show_board\n",
        "        self.turn = 0\n",
        "\n",
        "    def get_empty_positions(self):\n",
        "        return [(i, j) for i in range(GAME_ROW) for j in range(GAME_COL) if self.board[i, j] == EMPTY]\n",
        "\n",
        "    def is_winner(self, player):\n",
        "        symbol = player.symbol\n",
        "        for i in range(GAME_ROW):\n",
        "            if np.all(self.board[i, :] == symbol) or np.all(self.board[:, i] == symbol):\n",
        "                return True\n",
        "        if np.all(np.diag(self.board) == symbol) or np.all(np.diag(np.fliplr(self.board)) == symbol):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def is_draw(self):\n",
        "        return np.all(self.board != EMPTY)\n",
        "\n",
        "    def make_move(self, position):\n",
        "        if self.board[position] != EMPTY:\n",
        "            # Don't raise an exception, just return indicating an invalid move\n",
        "            return False\n",
        "        self.board[position] = self.current_player.symbol\n",
        "        return True\n",
        "\n",
        "    def switch_player(self):\n",
        "        self.current_player = self.player_x if self.current_player == self.player_o else self.player_o\n",
        "\n",
        "    def get_hash(self, board=None):\n",
        "        if board is None:\n",
        "            board = self.board\n",
        "        return ','.join(str(int(elem)) for elem in board.flatten())\n",
        "\n",
        "    def reset(self):\n",
        "        self.__init__(self.player_x, self.player_o, self.show_board)\n",
        "\n",
        "    def is_terminal(self):\n",
        "        # Check for a win in rows, columns, and diagonals\n",
        "        for i in range(GAME_ROW):\n",
        "            if np.all(self.board[i] == self.current_player.symbol) or \\\n",
        "               np.all(self.board[:, i] == self.current_player.symbol):\n",
        "                return True\n",
        "        if np.all(np.diag(self.board) == self.current_player.symbol) or \\\n",
        "           np.all(np.diag(np.fliplr(self.board)) == self.current_player.symbol):\n",
        "            return True\n",
        "        # Check for a draw (no empty positions left)\n",
        "        if not np.any(self.board == EMPTY):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def play(self):\n",
        "        self.reset()\n",
        "        while True:\n",
        "          position = self.current_player.move(self)\n",
        "          if not self.make_move(position):  # If move is invalid, skip to next turn\n",
        "            raise Exception(\"Something is wrong! No empty positions now!\")\n",
        "          self.turn+=1\n",
        "\n",
        "          if self.is_terminal():\n",
        "              if self.is_winner(self.current_player):\n",
        "                  self.winner = self.current_player.symbol\n",
        "                  print(f\"Player {self.current_player.symbol} wins!\")\n",
        "                  break  # Exit the loop immediately after a win\n",
        "\n",
        "              if self.is_draw():\n",
        "                  print(\"It's a draw!\")\n",
        "                  break  # Exit the loop immediately after a draw\n",
        "\n",
        "          if self.show_board:\n",
        "              print(f\"Turn {self.turn}: Player {self.current_player.symbol}\")\n",
        "              self.print_board()\n",
        "\n",
        "          self.switch_player()\n",
        "\n",
        "        if self.show_board:\n",
        "            self.print_board()  # Show the final board state\n",
        "\n",
        "    def print_board(self):\n",
        "        symbols = {EMPTY: ' ', PLAYER_X: 'X', PLAYER_O: 'O'}\n",
        "        for i in range(GAME_ROW):\n",
        "            print('|' + '|'.join(symbols[s] for s in self.board[i]) + '|')\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t2uA-1SRPx2"
      },
      "source": [
        "#### 0.2 Agent abstract class, all *agents* class inherit this one.\n",
        "* *RandomAgent*: perform random action\n",
        "* *AggressiveAgent*: choose the winning action\n",
        "* *DefensiveAgent*: stop opponent's winning action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfdUxuKtRYqW"
      },
      "outputs": [],
      "source": [
        "class Agent(ABC):\n",
        "    def __init__(self, symbol):\n",
        "        self.symbol = symbol\n",
        "        self.states_value = {}  # State values used by ValueIterationAgent\n",
        "\n",
        "    @abstractmethod\n",
        "    def move(self, game):\n",
        "        pass\n",
        "\n",
        "    def save_policy(self, file_name):\n",
        "        with open(file_name, 'wb') as f:\n",
        "            pickle.dump(self.states_value, f)\n",
        "\n",
        "    def load_policy(self, file_name):\n",
        "        with open(file_name, 'rb') as f:\n",
        "            self.states_value = pickle.load(f)\n",
        "\n",
        "class RandomAgent(Agent):\n",
        "    def move(self, game):\n",
        "        empty_cells = game.get_empty_positions()\n",
        "        if not empty_cells:\n",
        "            raise ValueError(\"No more moves left to play.\")\n",
        "        # Select a random move from the list of empty cells\n",
        "        return empty_cells[np.random.randint(len(empty_cells))]\n",
        "\n",
        "class AggressiveAgent(Agent):\n",
        "    def __init__(self, symbol):\n",
        "        super().__init__(symbol)\n",
        "\n",
        "    def move(self, game):\n",
        "        empty_positions = game.get_empty_positions()\n",
        "        board_copy = game.board.copy()\n",
        "        for position in empty_positions:\n",
        "            board_copy[position] = self.symbol\n",
        "            if game.is_winner(self):\n",
        "                return position\n",
        "            board_copy[position] = EMPTY  # Reset the position after check\n",
        "\n",
        "        # If no winning move found, return a random move\n",
        "        return empty_positions[np.random.choice(len(empty_positions))]\n",
        "\n",
        "class DefensiveAgent(Agent):\n",
        "    def __init__(self, symbol):\n",
        "        super().__init__(symbol)\n",
        "\n",
        "    def move(self, game):\n",
        "        opponent_symbol = PLAYER_O if self.symbol == PLAYER_X else PLAYER_X\n",
        "        empty_positions = game.get_empty_positions()\n",
        "        board_copy = game.board.copy()\n",
        "\n",
        "        # First, check if the opponent has a winning move and block it\n",
        "        for position in empty_positions:\n",
        "            board_copy[position] = opponent_symbol\n",
        "            if game.is_winner(self.__opponent()):\n",
        "                return position  # Block the opponent's winning move\n",
        "            board_copy[position] = EMPTY  # Reset the position after check\n",
        "\n",
        "        # If no blocking move is necessary, choose a random move\n",
        "        return empty_positions[np.random.choice(len(empty_positions))]\n",
        "\n",
        "    def __opponent(self):\n",
        "        # Private helper method to create a 'dummy' opponent with the opposite symbol\n",
        "        return RandomAgent(PLAYER_O if self.symbol == PLAYER_X else PLAYER_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulB1esGpTBDe"
      },
      "source": [
        "#### 0.3: Useful and example functions:\n",
        "Some may never been called"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMSydRNZTD2p"
      },
      "outputs": [],
      "source": [
        "def get_hash(board=None):\n",
        "    return ','.join(str(int(elem)) for elem in board.flatten())\n",
        "\n",
        "\n",
        "def get_hashes(boards):\n",
        "    return [get_hash(board) for board in boards]\n",
        "\n",
        "def valid_state(board, symbol):\n",
        "\n",
        "    # check the board state is valid\n",
        "    if symbol==PLAYER_X:\n",
        "        return (np.sum(board==PLAYER_X)==np.sum(board==PLAYER_O))\n",
        "    if symbol==PLAYER_O:\n",
        "        return (np.sum(board==PLAYER_X)-np.sum(board==PLAYER_O)==1)\n",
        "\n",
        "def next_symbol(board):\n",
        "    if (np.sum(board==PLAYER_X)==np.sum(board==PLAYER_O)):\n",
        "        return PLAYER_X\n",
        "    else:\n",
        "        return PLAYER_O\n",
        "\n",
        "def is_terminal(board):\n",
        "    # Check for a win in rows, columns, and diagonals\n",
        "    for i in range(GAME_ROW):\n",
        "        if abs(np.sum(board[i, :])) == 3 or abs(np.sum(board[:, i])) == 3:\n",
        "            return True\n",
        "    if abs(sum(np.diag(board))) == 3 or abs(sum(np.diag(np.fliplr(board)))) == 3:\n",
        "        return True\n",
        "    # Check for a draw\n",
        "    if not np.any(board == EMPTY):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def get_reward(board, symbol):\n",
        "    # Define opponent's symbol\n",
        "    opponent_symbol = PLAYER_O if symbol == PLAYER_X else PLAYER_X\n",
        "\n",
        "    # Check for current player's win\n",
        "    for i in range(GAME_ROW):\n",
        "        if sum(board[i, :]) == GAME_ROW * symbol or sum(board[:, i]) == GAME_COL * symbol:\n",
        "            return 1\n",
        "    if sum(np.diag(board)) == GAME_ROW * symbol or sum(np.diag(np.fliplr(board))) == GAME_COL * symbol:\n",
        "        return 1\n",
        "\n",
        "    # Check for opponent's win\n",
        "    for i in range(GAME_ROW):\n",
        "        if sum(board[i, :]) == GAME_ROW * opponent_symbol or sum(board[:, i]) == GAME_COL * opponent_symbol:\n",
        "            return -1\n",
        "    if sum(np.diag(board)) == GAME_ROW * opponent_symbol or sum(np.diag(np.fliplr(board))) == GAME_COL * opponent_symbol:\n",
        "        return -1\n",
        "\n",
        "    # Check for a draw\n",
        "    if is_terminal(board):\n",
        "        return 0\n",
        "\n",
        "    # For non-terminal states, the immediate reward is 0.\n",
        "    return 0\n",
        "\n",
        "\n",
        "def get_empty_positions(board):\n",
        "    return [(i, j) for i in range(GAME_ROW) for j in range(GAME_COL) if board[i, j] == EMPTY]\n",
        "\n",
        "def generate_next_boardstates(board, symbol):\n",
        "\n",
        "    # check the board state is valid\n",
        "    if symbol==PLAYER_X:\n",
        "        assert(np.sum(board==PLAYER_X)==np.sum(board==PLAYER_O))\n",
        "    if symbol==PLAYER_O:\n",
        "        assert(np.sum(board==PLAYER_X)-np.sum(board==PLAYER_O)==1)\n",
        "\n",
        "    # generate all next board states\n",
        "    all_empty_positions = get_empty_positions(board)\n",
        "    all_boards = np.tile(board, (len(all_empty_positions), 1, 1))\n",
        "    all_indices = np.concatenate(\n",
        "        [\n",
        "            np.expand_dims(np.arange(len(all_empty_positions)), axis=1),\n",
        "            np.array(all_empty_positions)\n",
        "        ], axis=1\n",
        "        )\n",
        "    all_boards[all_indices[:,0], all_indices[:,1], all_indices[:,2]] = symbol\n",
        "    all_boards = np.split(all_boards, all_boards.shape[0], axis=0)\n",
        "    return [np.squeeze(board) for board in all_boards]\n",
        "\n",
        "def generate_all_states(board, all_states=None, stop_step=None):\n",
        "\n",
        "    # assert(valid_state(board, symbol)) # validate the states and symbol\n",
        "\n",
        "    if all_states is None:\n",
        "        # all_states = {}\n",
        "        boards = [board]\n",
        "        state_hashes = [get_hash(board)]\n",
        "        p0 = 0\n",
        "        p1 = 1\n",
        "        p2 = p1\n",
        "        step = 0\n",
        "        step_symbol = next_symbol(board)\n",
        "\n",
        "    while p0!=p1:\n",
        "      for p_state in range(p0,p1):\n",
        "          # print(step)\n",
        "          # print('p_state:', p_state)\n",
        "          # print('board:', boards[p_state])\n",
        "          # print('step_symbol:', step_symbol)\n",
        "          # print(p1-p0)\n",
        "          # print('------------------------')\n",
        "          if is_terminal(boards[p_state]):\n",
        "              continue\n",
        "          next_boards = generate_next_boardstates(boards[p_state], step_symbol)\n",
        "          next_hashes = get_hashes(next_boards)\n",
        "\n",
        "          # print(next_boards)\n",
        "\n",
        "          boards+=next_boards\n",
        "          state_hashes+=next_hashes\n",
        "          p2 += len(next_boards)\n",
        "\n",
        "      step_symbol = PLAYER_X if step_symbol == PLAYER_O else PLAYER_O\n",
        "      p0 = p1\n",
        "      p1 = p2\n",
        "      step+=1\n",
        "\n",
        "      if stop_step is not None:\n",
        "        if step == stop_step:\n",
        "          break\n",
        "    return dict(zip(state_hashes, boards))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtdFtIMCU9hA"
      },
      "source": [
        "#### 0.4: Fenerate all states using the function **generate_all_states** and save the states hush table in the local path for the future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYr9IFtCVQOK",
        "outputId": "6e00f76d-df17-4187-9c6c-fe14660fd2b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In total,  5478 states\n"
          ]
        }
      ],
      "source": [
        "state_hush_fname = \"all_states_hush1.txt\"\n",
        "if os.path.isfile(state_hush_fname):\n",
        "    with open(state_hush_fname, 'rb') as f:\n",
        "        all_states = pickle.load(f)\n",
        "\n",
        "else:\n",
        "  temp_board = np.zeros((GAME_ROW, GAME_COL))\n",
        "  all_states = generate_all_states(temp_board)\n",
        "\n",
        "  # same hush table of all the states\n",
        "  with open(state_hush_fname, 'wb') as f:\n",
        "      pickle.dump(all_states, f)\n",
        "\n",
        "print(\"In total, \", len(all_states), \"states\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgZE3uSzeb5H"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zpn3yEZXGFy"
      },
      "source": [
        "### <font color=\"blue\"> **Task 1 (7 marks)**:</font> Value Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7lNh8ZYYn9_"
      },
      "source": [
        "#### <font color=\"blue\"> **Question 1:** </font> Write a value iteration agent in ValueIterationAgent which has been partially specified for you. Here you need to implement the train() & get_reward() methods. The former should perform **planning* using *value iteration and the latter should extract the policy and compute state values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-adhAyYaPTS"
      },
      "outputs": [],
      "source": [
        "class ValueIterationAgent(Agent):\n",
        "    def __init__(self, symbol, discount_factor=0.9, living_reward=-0.01):\n",
        "        super().__init__(symbol)\n",
        "        if 'all_states' in globals():\n",
        "            self.all_states = all_states\n",
        "        elif os.path.isfile(state_hush_fname):\n",
        "            with open(state_hush_fname, 'rb') as f:\n",
        "                self.all_states = pickle.load(f)\n",
        "        else:\n",
        "            raise Exception(\"No state hushes! Either run the code by order or create the state hush yourself\")\n",
        "\n",
        "        self.discount_factor = discount_factor  # Discount factor for future rewards\n",
        "        self.living_reward = living_reward  # Reward for living (negative for penalty)\n",
        "        self.value_function = {state: 0 for state in all_states.keys()}  # Initialize state values to 0\n",
        "\n",
        "        # self.all_states = all_states  # All possible states\n",
        "        self.win_reward=10.0;\n",
        "        self.lose_reward=-50.0;\n",
        "        self.living_reward=-1.00;\n",
        "        self.draw_reward=0.0;\n",
        "\n",
        "        self.policy = {}  # Initialize policy\n",
        "\n",
        "    def get_reward(self, board, symbol):\n",
        "        # Define opponent's symbol\n",
        "        opponent_symbol = PLAYER_O if symbol == PLAYER_X else PLAYER_X\n",
        "\n",
        "        # Check for current player's win\n",
        "        for i in range(GAME_ROW):\n",
        "            if sum(board[i, :]) == GAME_ROW * symbol or sum(board[:, i]) == GAME_COL * symbol:\n",
        "                return self.win_reward\n",
        "        if sum(np.diag(board)) == GAME_ROW * symbol or sum(np.diag(np.fliplr(board))) == GAME_COL * symbol:\n",
        "            return self.win_reward\n",
        "\n",
        "        # Check for opponent's win\n",
        "        # -- Your Code Here ---\n",
        "        for i in range(GAME_ROW):\n",
        "            if sum(board[i, :]) == GAME_ROW * opponent_symbol or sum(board[:, i]) == GAME_COL * opponent_symbol:\n",
        "                return self.lose_reward\n",
        "        if sum(np.diag(board)) == GAME_ROW * opponent_symbol or sum(np.diag(np.fliplr(board))) == GAME_COL * opponent_symbol:\n",
        "            return self.lose_reward\n",
        "\n",
        "        # Check for a draw\n",
        "        # -- Your Code Here --\n",
        "        if np.all(board != EMPTY):\n",
        "            return self.draw_reward\n",
        "\n",
        "        # For non-terminal states, the immediate reward is 0.\n",
        "        return 0\n",
        "\n",
        "\n",
        "    def train(self, threshold=0.00001):\n",
        "        # Value iteration algorithm\n",
        "        # -- Your Code Here--\n",
        "        while True:\n",
        "            new_value_function = {state: 0 for state in self.all_states.keys()}\n",
        "\n",
        "            for state in self.all_states.keys():\n",
        "                if is_terminal(np.array(self.all_states[state])):\n",
        "                    new_value_function[state] = self.get_reward(np.array(self.all_states[state]), self.symbol)\n",
        "                else:\n",
        "                    next_possible_states = generate_next_boardstates(\n",
        "                        np.array(self.all_states[state]), next_symbol(np.array(self.all_states[state]))\n",
        "                    )\n",
        "\n",
        "                    if next_symbol(np.array(self.all_states[state])) == self.symbol:\n",
        "                        new_value_function[state] = max(\n",
        "                            self.discount_factor * self.get_reward(np.array(self.all_states[state]), self.symbol)\n",
        "                            + self.value_function[get_hash(next_state)] for next_state in next_possible_states\n",
        "                        )\n",
        "                    else:\n",
        "                        new_value_function[state] = min(\n",
        "                            self.discount_factor * self.get_reward(np.array(self.all_states[state]), self.symbol)\n",
        "                            + self.value_function[get_hash(next_state)] for next_state in next_possible_states\n",
        "                        )\n",
        "\n",
        "            delta = max(abs(self.value_function[state] - new_value_function[state]) for state in self.all_states.keys())\n",
        "\n",
        "            self.value_function = new_value_function\n",
        "\n",
        "            if delta < threshold:\n",
        "                break\n",
        "\n",
        "        self.update_policy()\n",
        "\n",
        "\n",
        "    def update_policy(self):\n",
        "        for state in self.all_states.keys():\n",
        "            if not is_terminal(np.array(self.all_states[state])):\n",
        "                possible_actions = get_empty_positions(np.array(self.all_states[state]))\n",
        "                best_action = max(\n",
        "                    possible_actions, key=lambda action: self.calculate_q_value(state, action)\n",
        "                ) if self.symbol == next_symbol(np.array(self.all_states[state])) else min(\n",
        "                    possible_actions, key=lambda action: self.calculate_q_value(state, action)\n",
        "                )\n",
        "                self.policy[state] = best_action\n",
        "\n",
        "    def calculate_q_value(self, state, action):\n",
        "        next_state = np.array(self.all_states[state]).copy()\n",
        "        next_state[action] = next_symbol(np.array(self.all_states[state]))\n",
        "        reward = self.get_reward(next_state, next_symbol(np.array(self.all_states[state])))\n",
        "        return reward + self.discount_factor * self.value_function[get_hash(next_state)]\n",
        "\n",
        "    def move(self, game):\n",
        "        # Return the move based on the current policy\n",
        "        current_state = game.get_hash()\n",
        "        if current_state in self.policy:\n",
        "            return self.policy[current_state]\n",
        "        else:\n",
        "            # In case current state is not in the policy, choose a random move\n",
        "            empty_positions = game.get_empty_positions()\n",
        "            return empty_positions[np.random.choice(len(empty_positions))]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjfOjBUnXr7-"
      },
      "source": [
        "#### <font color=\"blue\">Q1.1 (3/7): Run the following example of a Value Iteration \"X\" player against a Random \"O\" agent </font>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1Tm1EjIolSl",
        "outputId": "43dfb3b5-e28d-43e2-cfa5-8844baed3be9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Player 1 wins!\n"
          ]
        }
      ],
      "source": [
        "player_x = ValueIterationAgent(PLAYER_X)  # This is the value iteration agent\n",
        "player_o = RandomAgent(PLAYER_O)  # This is the random agent\n",
        "\n",
        "game = Game(player_x, player_o)\n",
        "# print(game.board)\n",
        "\n",
        "# Compute the policy using value iteration only for the value iteration agent\n",
        "player_x.train()  # We only need to compute this for player O\n",
        "\n",
        "# Play the game\n",
        "game.play()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXulxNJPgA2b"
      },
      "source": [
        "#### <font color=\"blue\"> Q1.2 (3/7): Based on the example (Game 0: RandomAgent \"O\" v.s. ValueIterationAgent \"X\") above, run the following game: </font>\n",
        "* Game1: RandomAgent \"X\" v.s. ValueIterationAgent \"O\"\n",
        "* Game2: ValueIterationAgent \"X\" v.s. AggressiveAgent \"O\"\n",
        "* Game3: ValueIterationAgent \"O\" v.s. AggressiveAgent \"X\"\n",
        "* Game4: ValueIterationAgent \"X\" v.s. DefensiveAgent \"O\"\n",
        "* Game 5: ValueIterationAgent \"O\" v.s. DefensiveAgent \"X\"\n",
        "\n",
        "Use the one single code cell *below*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Cdq_YzynN10",
        "outputId": "dc10d996-b0a7-4f45-be36-7e8357f5d14e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n"
          ]
        }
      ],
      "source": [
        "# Game 1:\n",
        "player_x = RandomAgent(PLAYER_X)  # This is the random agent\n",
        "player_o = ValueIterationAgent(PLAYER_O)  # This is the value iteration agent\n",
        "game1 = Game(player_x, player_o)\n",
        "# Compute the policy using value iteration only for the value iteration agent\n",
        "player_o.train()\n",
        "game1.play() # Play the game\n",
        "\n",
        "# Game 2:\n",
        "player_x = ValueIterationAgent(PLAYER_X)  # This is the value iteration agent\n",
        "player_o = AggressiveAgent(PLAYER_O)  # This is the aggressive agent\n",
        "game2 = Game(player_x, player_o)\n",
        "# Compute the policy using value iteration only for the value iteration agent\n",
        "player_x.train()\n",
        "game2.play() # Play the game\n",
        "\n",
        "# Game 3:\n",
        "player_o = ValueIterationAgent(PLAYER_O)  # This is the value iteration agent\n",
        "player_x = AggressiveAgent(PLAYER_X)  # This is the aggresive agent\n",
        "game3 = Game(player_o, player_x)\n",
        "# Compute the policy using value iteration only for the value iteration agent\n",
        "player_o.train()\n",
        "game3.play() # Play the game\n",
        "\n",
        "# Game 4:\n",
        "player_x = ValueIterationAgent(PLAYER_X)  # This is the value iteration agent\n",
        "player_o = DefensiveAgent(PLAYER_O)  # This is the defensive agent\n",
        "game4 = Game(player_x, player_o)\n",
        "# Compute the policy using value iteration only for the value iteration agent\n",
        "player_x.train()\n",
        "game4.play() # Play the game\n",
        "\n",
        "# Game 5:\n",
        "player_o = ValueIterationAgent(PLAYER_O)  # This is the value iteration agent\n",
        "player_x = DefensiveAgent(PLAYER_X)  # This is the defensive agent\n",
        "game5 = Game(player_o, player_x)\n",
        "# Compute the policy using value iteration only for the value iteration agent\n",
        "player_o.train()\n",
        "game5.play() # Play the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCD_2WhQnOgT"
      },
      "source": [
        "#### <font color=\"blue\"> Q1.3 (1/7): Repeat the games (Game 0-5) above 50 rounds each Game. Using ValueIterationAgent, print out number of *wins*, *losts* and *draw* </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfHFssjEhac1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH5372syA3M1",
        "outputId": "d1087b9b-dd66-4902-da4b-44c5cad89b94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Game 0: Wins: 50, Losses: 0, Draws: 0\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "It's a draw!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "It's a draw!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Game 1: Wins: 0, Losses: 42, Draws: 8\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Game 2: Wins: 50, Losses: 0, Draws: 0\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Game 3: Wins: 0, Losses: 41, Draws: 9\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Game 4: Wins: 50, Losses: 0, Draws: 0\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Game 5: Wins: 0, Losses: 40, Draws: 10\n"
          ]
        }
      ],
      "source": [
        "# Q1.2 1-5:\n",
        "\n",
        "game.show_board = False # Disable printing board, don't change\n",
        "\n",
        "# -- Your Code Here ---\n",
        "# Repeat each game 50 times\n",
        "def play_games(player_x, player_o, rounds=50):\n",
        "    wins = losses = draws = 0\n",
        "    for _ in range(rounds):\n",
        "        game = Game(player_x, player_o)\n",
        "        game.show_board = False\n",
        "        game.play()\n",
        "        if game.winner == player_x.symbol:\n",
        "            wins += 1\n",
        "        elif game.winner == player_o.symbol:\n",
        "            losses += 1\n",
        "        else:\n",
        "            draws += 1\n",
        "    return wins, losses, draws\n",
        "\n",
        "# Game 0: RandomAgent \"O\" vs. ValueIterationAgent \"X\"\n",
        "player_x = ValueIterationAgent(PLAYER_X)\n",
        "player_o = RandomAgent(PLAYER_O)\n",
        "player_x.train()\n",
        "wins0, losses0, draws0 = play_games(player_x, player_o)\n",
        "print(f\"Game 0: Wins: {wins0}, Losses: {losses0}, Draws: {draws0}\")\n",
        "\n",
        "# Game 1: RandomAgent \"X\" vs. ValueIterationAgent \"O\"\n",
        "player_x = RandomAgent(PLAYER_X)\n",
        "player_o = ValueIterationAgent(PLAYER_O)\n",
        "player_o.train()\n",
        "wins1, losses1, draws1 = play_games(player_x, player_o)\n",
        "print(f\"Game 1: Wins: {wins1}, Losses: {losses1}, Draws: {draws1}\")\n",
        "\n",
        "# Game 2: ValueIterationAgent \"X\" vs. AggressiveAgent \"O\"\n",
        "player_x = ValueIterationAgent(PLAYER_X)\n",
        "player_o = AggressiveAgent(PLAYER_O)\n",
        "player_x.train()\n",
        "wins2, losses2, draws2 = play_games(player_x, player_o)\n",
        "print(f\"Game 2: Wins: {wins2}, Losses: {losses2}, Draws: {draws2}\")\n",
        "\n",
        "# Game 3: ValueIterationAgent \"O\" vs. AggressiveAgent \"X\"\n",
        "player_x = AggressiveAgent(PLAYER_X)\n",
        "player_o = ValueIterationAgent(PLAYER_O)\n",
        "player_o.train()\n",
        "wins3, losses3, draws3 = play_games(player_x, player_o)\n",
        "print(f\"Game 3: Wins: {wins3}, Losses: {losses3}, Draws: {draws3}\")\n",
        "\n",
        "# Game 4: ValueIterationAgent \"X\" vs. DefensiveAgent \"O\"\n",
        "player_x = ValueIterationAgent(PLAYER_X)\n",
        "player_o = DefensiveAgent(PLAYER_O)\n",
        "player_x.train()\n",
        "wins4, losses4, draws4 = play_games(player_x, player_o)\n",
        "print(f\"Game 4: Wins: {wins4}, Losses: {losses4}, Draws: {draws4}\")\n",
        "\n",
        "# Game 5: ValueIterationAgent \"O\" vs. DefensiveAgent \"X\"\n",
        "player_x = DefensiveAgent(PLAYER_X)\n",
        "player_o = ValueIterationAgent(PLAYER_O)\n",
        "player_o.train()\n",
        "wins5, losses5, draws5 = play_games(player_x, player_o)\n",
        "print(f\"Game 5: Wins: {wins5}, Losses: {losses5}, Draws: {draws5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHWrhsv2hZHp"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNeTi_PNjG0Q"
      },
      "source": [
        "### <font color=\"blue\"> **Task 2** (7 marks):</font>  Policy Iteration\n",
        "\n",
        "Write a Policy Iteration agent in PolicyIterationAgent by implementing the policy_evaluation(), policy_improvement(), train() methods. The policy_evaluation() method should evaluate the current policy (see your lecture notes). The current values for the current policy should be stored in the provided policyValues map. The policy_improvement() method performs the Policy improvement step, and updates curPolicy. The train() method is the planning process, once done, an optimal policy should be saved in the agent object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EndhRUKJmn51"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class PolicyIterationAgent(Agent):\n",
        "    def __init__(self, symbol, discount_factor=0.9, living_reward=-0.01):\n",
        "        super().__init__(symbol)\n",
        "\n",
        "        if 'all_states' in globals():\n",
        "            self.all_states = all_states\n",
        "        elif os.path.isfile(state_hush_fname):\n",
        "            with open(state_hush_fname, 'rb') as f:\n",
        "                self.all_states = pickle.load(f)\n",
        "        else:\n",
        "            raise Exception(\"No state hushes! Either run the code by order or create the state hush yourself\")\n",
        "\n",
        "        self.discount_factor = discount_factor  # Discount factor for future rewards\n",
        "        self.living_reward = living_reward  # Reward for living (negative for penalty)\n",
        "        self.value_function = {state: 0 for state in all_states.keys()}  # Initialize state values to 0\n",
        "\n",
        "        # self.all_states = all_states  # All possible states\n",
        "        self.win_reward=10.0;\n",
        "        self.lose_reward=-50.0;\n",
        "        self.living_reward=-1.00;\n",
        "        self.draw_reward=0.0;\n",
        "\n",
        "        self.all_states = all_states  # All possible states\n",
        "        self.discount_factor = discount_factor  # Discount factor for future rewards\n",
        "        # self.living_reward = living_reward  # Living reward (negative for penalty)\n",
        "        self.value_function = {state: 0 for state in all_states.keys()}  # Initialize state values to 0\n",
        "        # self.policy = {state: np.random.choice(get_empty_positions(board))\n",
        "        #                for state, board in all_states.items() if not is_terminal(board)}  # Random initial policy\n",
        "        # # Choosing a random tuple from the list of empty positions\n",
        "        self.policy = {state: random.choice(get_empty_positions(board))\n",
        "                   for state, board in all_states.items() if not is_terminal(board)}  # Random initial policy\n",
        "\n",
        "    def get_reward(self, board, symbol):\n",
        "        # Define opponent's symbol\n",
        "        opponent_symbol = PLAYER_O if symbol == PLAYER_X else PLAYER_X\n",
        "\n",
        "        # Check for current player's win\n",
        "        for i in range(GAME_ROW):\n",
        "            if sum(board[i, :]) == GAME_ROW * symbol or sum(board[:, i]) == GAME_COL * symbol:\n",
        "                return self.win_reward\n",
        "        if sum(np.diag(board)) == GAME_ROW * symbol or sum(np.diag(np.fliplr(board))) == GAME_COL * symbol:\n",
        "            return self.win_reward\n",
        "\n",
        "        # Check for opponent's win\n",
        "        for i in range(GAME_ROW):\n",
        "            if np.all(board[i, :] == opponent_symbol) or np.all(board[:, i] == opponent_symbol):\n",
        "                return self.lose_reward\n",
        "        if np.all(np.diag(board) == opponent_symbol) or np.all(np.diag(np.fliplr(board)) == opponent_symbol):\n",
        "            return self.lose_reward\n",
        "\n",
        "        # Check for a draw\n",
        "        if not np.any(board == EMPTY):\n",
        "            return self.draw_reward\n",
        "\n",
        "        # For non-terminal states, the immediate reward is 0.\n",
        "        return 0\n",
        "\n",
        "    def policy_evaluation(self, threshold=0.0001):\n",
        "        # -- Your Code Here ---\n",
        "        # Perform policy evaluation to update the value function\n",
        "        while True:\n",
        "            delta = 0\n",
        "            for state in self.all_states.keys():\n",
        "                if is_terminal(np.array(self.all_states[state])):\n",
        "                    continue\n",
        "\n",
        "                old_value = self.value_function[state]\n",
        "                action = self.policy[state]\n",
        "\n",
        "                next_state = np.array(self.all_states[state]).copy()\n",
        "                next_state[action] = next_symbol(np.array(self.all_states[state]))\n",
        "\n",
        "                reward = self.get_reward(next_state, next_symbol(np.array(self.all_states[state])))\n",
        "                self.value_function[state] = reward + self.discount_factor * self.value_function[get_hash(next_state)]\n",
        "\n",
        "                delta = max(delta, abs(old_value - self.value_function[state]))\n",
        "\n",
        "            if delta < threshold:\n",
        "                break\n",
        "\n",
        "\n",
        "    def policy_improvement(self):\n",
        "        # -- Your Code Here --\n",
        "        # Update the policy based on the updated value function\n",
        "        policy_stable = True\n",
        "        for state in self.all_states.keys():\n",
        "            if is_terminal(np.array(self.all_states[state])):\n",
        "                continue\n",
        "\n",
        "            old_action = self.policy[state]\n",
        "            possible_actions = get_empty_positions(np.array(self.all_states[state]))\n",
        "\n",
        "            # Choose a winning move and adjust the policy\n",
        "            winning_moves = [action for action in possible_actions\n",
        "                             if self.get_reward(np.array(self.all_states[state]), self.symbol) == self.win_reward]\n",
        "            if winning_moves:\n",
        "                best_action = random.choice(winning_moves)\n",
        "            else:\n",
        "                best_action = max(\n",
        "                    possible_actions, key=lambda action: self.calculate_q_value(state, action)\n",
        "                ) if self.symbol == next_symbol(np.array(self.all_states[state])) else min(\n",
        "                    possible_actions, key=lambda action: self.calculate_q_value(state, action)\n",
        "                )\n",
        "\n",
        "            self.policy[state] = best_action\n",
        "\n",
        "            if old_action != self.policy[state]:\n",
        "                policy_stable = False\n",
        "\n",
        "        return policy_stable\n",
        "\n",
        "    def train(self):\n",
        "        while True:\n",
        "            self.policy_evaluation()\n",
        "            if self.policy_improvement():\n",
        "                break\n",
        "\n",
        "    def calculate_q_value(self, state, action):\n",
        "        next_state = np.array(self.all_states[state]).copy()\n",
        "        next_state[action] = next_symbol(np.array(self.all_states[state]))\n",
        "        reward = self.get_reward(next_state, next_symbol(np.array(self.all_states[state])))\n",
        "        return reward + self.discount_factor * self.value_function[get_hash(next_state)]\n",
        "\n",
        "    def move(self, game):\n",
        "        # Return the move based on the current policy\n",
        "        current_state = game.get_hash()\n",
        "        if current_state in self.policy:\n",
        "            return self.policy[current_state]\n",
        "        else:\n",
        "            # If the current state is not in the policy, choose a random move\n",
        "            empty_positions = game.get_empty_positions()\n",
        "            return empty_positions[np.random.choice(len(empty_positions))]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUDOQc24l5Wy"
      },
      "source": [
        "#### <font color=\"blue\">Q2.1 (3/7): Run the following: Iteration \"X\" player against a Random \"O\" agent </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7Xlh2s1w9xu",
        "outputId": "d5d71291-ff85-4bdb-c217-41094d824d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Player 1 wins!\n"
          ]
        }
      ],
      "source": [
        "player_o = RandomAgent(PLAYER_O)  # This is the random agent\n",
        "player_x = PolicyIterationAgent(PLAYER_X)  # This is the value iteration agent\n",
        "\n",
        "# player_x = PolicyIterationAgent(PLAYER_X)  # This is the policy iteration agent\n",
        "# player_o = RandomAgent(PLAYER_O)  # This is the random agent\n",
        "\n",
        "game = Game(player_x, player_o)\n",
        "# print(game.board)\n",
        "\n",
        "# Compute the policy using value iteration only for the policy iteration agent\n",
        "player_x.train()  # We only need to compute this for player O\n",
        "\n",
        "# Play the game\n",
        "\n",
        "game.play()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3DVPAExmqVa"
      },
      "source": [
        "#### <font color=\"blue\"> Q2.2 (3/7): Based on the example (Game 0: RandomAgent \"O\" v.s. PlicyIterationAgent \"X\") above, run the following game: </font>\n",
        "* Game1: RandomAgent \"X\" v.s. PolicyIterationAgent \"O\"\n",
        "* Game2: PolicyIterationAgent \"X\" v.s. AggressiveAgent \"O\"\n",
        "* Game3: PolicyIterationAgent \"O\" v.s. AggressiveAgent \"X\"\n",
        "* Game4: PolicyIterationAgent \"X\" v.s. DefensiveAgent \"O\"\n",
        "* Game 5: PolicyIterationAgent \"O\" v.s. DefensiveAgent \"X\"\n",
        "\n",
        "Use the one single code cell *below*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6mgJfvYnfMQ",
        "outputId": "efbf0227-b7cb-4c76-d669-fe0d84a5775b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n"
          ]
        }
      ],
      "source": [
        "# Game 1:\n",
        "player_x = RandomAgent(PLAYER_X)\n",
        "player_o = PolicyIterationAgent(PLAYER_O)\n",
        "game1 = Game(player_x, player_o)\n",
        "player_o.train()\n",
        "game1.play()\n",
        "\n",
        "# Game 2:\n",
        "player_o = AggressiveAgent(PLAYER_O)\n",
        "player_x = PolicyIterationAgent(PLAYER_X)\n",
        "game2 = Game(player_x, player_o)\n",
        "player_x.train()\n",
        "game2.play()\n",
        "\n",
        "# Game 3:\n",
        "player_o = PolicyIterationAgent(PLAYER_O)\n",
        "player_x = AggressiveAgent(PLAYER_X)\n",
        "game3 = Game(player_x, player_o)\n",
        "player_o.train()\n",
        "game3.play()\n",
        "\n",
        "# Game 4:\n",
        "player_o = DefensiveAgent(PLAYER_O)\n",
        "player_x = PolicyIterationAgent(PLAYER_X)\n",
        "game4 = Game(player_x, player_o)\n",
        "player_x.train()\n",
        "game4.play()\n",
        "\n",
        "# Game 5:\n",
        "player_o = PolicyIterationAgent(PLAYER_O)\n",
        "player_x = DefensiveAgent(PLAYER_X)\n",
        "game5 = Game(player_x, player_o)\n",
        "player_o.train()\n",
        "game5.play()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crIFJl3_nlcx"
      },
      "source": [
        "#### <font color=\"blue\"> Q2.3 (1/7): Repeat the games (Game 0-5) above 50 rounds each Game. Using PolicyIterationAgent, print out number of *wins*, *losts* and *draw* </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCyXqiiznLei",
        "outputId": "a58daf07-3dbe-4973-d71c-891f7cbd9aaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Game 0: Wins: 50, Losses: 0, Draws: 0\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Game 1: Wins: 8, Losses: 42, Draws: 0\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Game 2: Wins: 50, Losses: 0, Draws: 0\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Game 3: Wins: 10, Losses: 40, Draws: 0\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Game 4: Wins: 49, Losses: 1, Draws: 0\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Game 5: Wins: 15, Losses: 35, Draws: 0\n"
          ]
        }
      ],
      "source": [
        "game.show_board = False\n",
        "\n",
        "# -- Your Code Here ---\n",
        "# Repeat each game 50 times\n",
        "def play_games(player_x, player_o, rounds=50):\n",
        "    wins = losses = draws = 0\n",
        "    for _ in range(rounds):\n",
        "        game = Game(player_x, player_o)\n",
        "        game.show_board = False\n",
        "        game.play()\n",
        "        if game.winner == player_x.symbol:\n",
        "            wins += 1\n",
        "        elif game.winner == player_o.symbol:\n",
        "            losses += 1\n",
        "        else:\n",
        "            draws += 1\n",
        "    return wins, losses, draws\n",
        "\n",
        "# Game 0: RandomAgent \"O\" vs. ValueIterationAgent \"X\"\n",
        "player_x = PolicyIterationAgent(PLAYER_X)\n",
        "player_o = RandomAgent(PLAYER_O)\n",
        "player_x.train()\n",
        "wins0, losses0, draws0 = play_games(player_x, player_o)\n",
        "print(f\"Game 0: Wins: {wins0}, Losses: {losses0}, Draws: {draws0}\")\n",
        "\n",
        "# Game 1: RandomAgent \"X\" vs. ValueIterationAgent \"O\"\n",
        "player_x = RandomAgent(PLAYER_X)\n",
        "player_o = PolicyIterationAgent(PLAYER_O)\n",
        "player_o.train()\n",
        "wins1, losses1, draws1 = play_games(player_x, player_o)\n",
        "print(f\"Game 1: Wins: {wins1}, Losses: {losses1}, Draws: {draws1}\")\n",
        "\n",
        "# Game 2: ValueIterationAgent \"X\" vs. AggressiveAgent \"O\"\n",
        "player_x = PolicyIterationAgent(PLAYER_X)\n",
        "player_o = AggressiveAgent(PLAYER_O)\n",
        "player_x.train()\n",
        "wins2, losses2, draws2 = play_games(player_x, player_o)\n",
        "print(f\"Game 2: Wins: {wins2}, Losses: {losses2}, Draws: {draws2}\")\n",
        "\n",
        "# Game 3: ValueIterationAgent \"O\" vs. AggressiveAgent \"X\"\n",
        "player_x = AggressiveAgent(PLAYER_X)\n",
        "player_o = PolicyIterationAgent(PLAYER_O)\n",
        "player_o.train()\n",
        "wins3, losses3, draws3 = play_games(player_x, player_o)\n",
        "print(f\"Game 3: Wins: {wins3}, Losses: {losses3}, Draws: {draws3}\")\n",
        "\n",
        "# Game 4: ValueIterationAgent \"X\" vs. DefensiveAgent \"O\"\n",
        "player_x = PolicyIterationAgent(PLAYER_X)\n",
        "player_o = DefensiveAgent(PLAYER_O)\n",
        "player_x.train()\n",
        "wins4, losses4, draws4 = play_games(player_x, player_o)\n",
        "print(f\"Game 4: Wins: {wins4}, Losses: {losses4}, Draws: {draws4}\")\n",
        "\n",
        "# Game 5: ValueIterationAgent \"O\" vs. DefensiveAgent \"X\"\n",
        "player_x = DefensiveAgent(PLAYER_X)\n",
        "player_o = PolicyIterationAgent(PLAYER_O)\n",
        "player_o.train()\n",
        "wins5, losses5, draws5 = play_games(player_x, player_o)\n",
        "print(f\"Game 5: Wins: {wins5}, Losses: {losses5}, Draws: {draws5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zuio47AnyyF"
      },
      "source": [
        "### <font color=\"blue\"> **Task 2** (6 marks):</font>  Q-Learn\n",
        "\n",
        "Write a QLearn agent in QLearnIterationAgent. No specific requirements of functions, but the planning process have to be done in a plan() function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZkZXUbyy-UO"
      },
      "outputs": [],
      "source": [
        "class QLearningAgent(Agent):\n",
        "\n",
        "    def __init__(self, symbol, alpha=0.4, gamma=0.9, epsilon=0.1, living_penalty=-1):\n",
        "        super().__init__(symbol)\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.gamma = gamma  # Discount factor\n",
        "        self.epsilon = epsilon  # Epsilon for the epsilon-greedy policy\n",
        "        self.Q = {}  # Initialize Q-table\n",
        "        self.living_penalty = living_penalty\n",
        "        self.win_reward = 10.0\n",
        "        self.lose_reward = -50.0\n",
        "        self.draw_reward = 0.0\n",
        "        self.initial_state = np.zeros((GAME_ROW, GAME_COL), dtype=int)  # Initialize the initial state\n",
        "        self.current_symbol = symbol  # The symbol of the current player\n",
        "\n",
        "\n",
        "    # -- Your Code Here---\n",
        "    def plan(self, state_hash, action, new_state_hash, reward):\n",
        "        # Q-learning update\n",
        "        if state_hash not in self.Q:\n",
        "            self.Q[state_hash] = {}\n",
        "        if new_state_hash not in self.Q:\n",
        "            self.Q[new_state_hash] = {}\n",
        "\n",
        "        old_value = self.Q[state_hash].get(action, 0)\n",
        "        next_max = max(self.Q[new_state_hash].values(), default=0)\n",
        "\n",
        "        new_value = (1 - self.alpha) * old_value + self.alpha * (reward + self.gamma * next_max)\n",
        "        self.Q[state_hash][action] = new_value\n",
        "\n",
        "\n",
        "    def choose_action(self, state_hash, available_actions):\n",
        "        if state_hash not in self.Q or np.random.rand() < self.epsilon:\n",
        "            return random.choice(available_actions)\n",
        "        else:\n",
        "            return max(available_actions, key=lambda a: self.Q[state_hash].get(a, 0))\n",
        "\n",
        "    def get_reward(self, state, symbol):\n",
        "        opponent_symbol = -symbol\n",
        "\n",
        "        # Check for a win\n",
        "        for i in range(GAME_ROW):\n",
        "            if np.all(state[i, :] == symbol) or np.all(state[:, i] == symbol):\n",
        "                return self.win_reward\n",
        "        if np.all(np.diag(state) == symbol) or np.all(np.diag(np.fliplr(state)) == symbol):\n",
        "            return self.win_reward\n",
        "\n",
        "        # Check for a loss\n",
        "        for i in range(GAME_ROW):\n",
        "            if np.all(state[i, :] == opponent_symbol) or np.all(state[:, i] == opponent_symbol):\n",
        "                return self.lose_reward\n",
        "        if np.all(np.diag(state) == opponent_symbol) or np.all(np.diag(np.fliplr(state)) == opponent_symbol):\n",
        "            return self.lose_reward\n",
        "\n",
        "        # Check for a draw\n",
        "        if not any(0 in row for row in state):\n",
        "            return self.draw_reward\n",
        "\n",
        "        # For non-terminal states, the immediate reward is 0.\n",
        "        return 0\n",
        "\n",
        "    def train(self, num_episodes=100000):\n",
        "        # -- Your Code Here --\n",
        "        for _ in range(num_episodes):\n",
        "            state = self.initial_state.copy()\n",
        "            state_hash = self.hash_state(state)\n",
        "\n",
        "            while not is_terminal(state):\n",
        "                available_actions = self.get_available_actions(state)\n",
        "\n",
        "                if np.random.rand() < self.epsilon:\n",
        "                    action = random.choice(available_actions)\n",
        "                else:\n",
        "                    action = self.choose_action(state_hash, available_actions)\n",
        "\n",
        "                new_state, reward, _ = self.make_move(state, action, self.current_symbol)\n",
        "                new_state_hash = self.hash_state(new_state)\n",
        "\n",
        "                self.plan(state_hash, action, new_state_hash, reward)\n",
        "\n",
        "                state = new_state\n",
        "                state_hash = new_state_hash\n",
        "\n",
        "\n",
        "    def hash_state(self, state):\n",
        "        return str(state.reshape(GAME_ROW * GAME_COL))\n",
        "\n",
        "    def get_available_actions(self, state):\n",
        "        return [(i, j) for i in range(GAME_ROW) for j in range(GAME_COL) if state[i, j] == EMPTY]\n",
        "\n",
        "    def make_move(self, state, action, symbol):\n",
        "        new_state = np.array(state)\n",
        "        new_state[action] = symbol\n",
        "        reward = self.get_reward(new_state, symbol)\n",
        "        done = is_terminal(new_state)\n",
        "        return new_state, reward, done\n",
        "\n",
        "\n",
        "    def move(self, game):\n",
        "        # Extract the board from the Game object\n",
        "        board = game.board\n",
        "        state_hash = self.hash_state(board)\n",
        "        available_actions = self.get_available_actions(board)\n",
        "\n",
        "        if not available_actions:\n",
        "            raise ValueError(\"No available actions to make a move.\")\n",
        "\n",
        "        # Choose the best action based on the Q-table\n",
        "        action = self.choose_action(state_hash, available_actions)\n",
        "\n",
        "        # Convert action to the format expected by Game's make_move method (e.g., (row, col))\n",
        "        return action\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiHdvxkMqosW"
      },
      "source": [
        "#### <font color=\"blue\">Q3.1 (3/6): Run the following example: Iteration \"X\" player against a Random \"O\" agent </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeVoMtf23UkV",
        "outputId": "3e97e00f-f056-4ef3-9c09-071407dac966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Player 1 wins!\n"
          ]
        }
      ],
      "source": [
        "# Initialize the QLearningAgent with its symbol (X or O)\n",
        "q_learning_agent = QLearningAgent(PLAYER_X)\n",
        "\n",
        "# Assume there is a random agent for the opponent\n",
        "random_agent = RandomAgent(PLAYER_O)\n",
        "\n",
        "# Initialize the game environment with both agents\n",
        "game = Game(q_learning_agent, random_agent)\n",
        "\n",
        "# Train the QLearningAgent with a function that simulates playing the game\n",
        "# The train function would need to be implemented to simulate games within the agent\n",
        "q_learning_agent.train()\n",
        "\n",
        "# Use the game's play function to start playing\n",
        "game.play()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nClnharq80A"
      },
      "source": [
        "#### <font color=\"blue\"> Q3.2 (2/6): Based on the example (Game 0: RandomAgent \"O\" v.s. QLearnAgent \"X\") above, run the following game: </font>\n",
        "* Game1: RandomAgent \"X\" v.s. QLearnAgent \"O\"\n",
        "* Game2: QLearnAgent \"X\" v.s. AggressiveAgent \"O\"\n",
        "* Game3: QLearnAgent \"O\" v.s. AggressiveAgent \"X\"\n",
        "* Game4: QLearnAgent \"X\" v.s. DefensiveAgent \"O\"\n",
        "* Game 5: QLearnAgent \"O\" v.s. DefensiveAgent \"X\"\n",
        "\n",
        "Use the one single code cell *below*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4WgO8SHrPgG",
        "outputId": "c4e686b1-785d-4bba-bbe4-756d5d28b26c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n"
          ]
        }
      ],
      "source": [
        "# Game 1:\n",
        "q_learning_agent = QLearningAgent(PLAYER_O) # Initialize the QLearningAgent with its symbol O\n",
        "random_agent = RandomAgent(PLAYER_X) # Assume there is a random agent for the opponent\n",
        "game1 = Game(q_learning_agent, random_agent) # Initialize the game environment with both agents\n",
        "q_learning_agent.train() # Train the QLearningAgent with a function that simulates playing the game\n",
        "game1.play() # Use the game's play function to start playing\n",
        "\n",
        "# Game 2:\n",
        "q_learning_agent = QLearningAgent(PLAYER_X) # Initialize the QLearningAgent with its symbol X\n",
        "aggressive_agent = AggressiveAgent(PLAYER_O) # Assume there is an aggressive agent for the opponent\n",
        "game2 = Game(q_learning_agent, aggressive_agent) # Initialize the game environment with both agents\n",
        "q_learning_agent.train() # Train the QLearningAgent with a function that simulates playing the game\n",
        "game2.play() # Use the game's play function to start playing\n",
        "\n",
        "# Game 3:\n",
        "q_learning_agent = QLearningAgent(PLAYER_O) # Initialize the QLearningAgent with its symbol O\n",
        "aggressive_agent = AggressiveAgent(PLAYER_X) # Assume there is a random agent for the opponent\n",
        "game3 = Game(q_learning_agent, aggressive_agent) # Initialize the game environment with both agents\n",
        "q_learning_agent.train() # Train the QLearningAgent with a function that simulates playing the game\n",
        "game3.play() # Use the game's play function to start playing\n",
        "\n",
        "# Game 4:\n",
        "q_learning_agent = QLearningAgent(PLAYER_X) # Initialize the QLearningAgent with its symbol X\n",
        "defensive_agent = DefensiveAgent(PLAYER_O) # Assume there is an defensive agent for the opponent\n",
        "game4 = Game(q_learning_agent, defensive_agent) # Initialize the game environment with both agents\n",
        "q_learning_agent.train() # Train the QLearningAgent with a function that simulates playing the game\n",
        "game4.play() # Use the game's play function to start playing\n",
        "\n",
        "# Game 5:\n",
        "q_learning_agent = QLearningAgent(PLAYER_O) # Initialize the QLearningAgent with its symbol O\n",
        "defensive_agent = DefensiveAgent(PLAYER_X) # Assume there is a defensive agent for the opponent\n",
        "game5 = Game(q_learning_agent, defensive_agent) # Initialize the game environment with both agents\n",
        "q_learning_agent.train() # Train the QLearningAgent with a function that simulates playing the game\n",
        "game5.play() # Use the game's play function to start playing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZAp7JyorMac"
      },
      "source": [
        "#### <font color=\"blue\"> Q3.3 (1/7): Repeat the games (Game 0-5) above 50 rounds each Game. Using QLearnAgent, print out number of *wins*, *losts* and *draw* </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnNjSEt2xEo4",
        "outputId": "a8bffa35-c6b2-47f1-c2ea-25c6b79f9d58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Game 0: Wins: 29, Losses: 14, Draws: 7\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Game 1: Wins: 29, Losses: 16, Draws: 5\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Game 2: Wins: 33, Losses: 11, Draws: 6\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Game 3: Wins: 29, Losses: 16, Draws: 5\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Game 4: Wins: 33, Losses: 13, Draws: 4\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "It's a draw!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Player 1 wins!\n",
            "Player 1 wins!\n",
            "Player -1 wins!\n",
            "Player -1 wins!\n",
            "Game 5: Wins: 18, Losses: 24, Draws: 8\n"
          ]
        }
      ],
      "source": [
        "game.show_board = False\n",
        "\n",
        "# -- Your Code Here --\n",
        "\n",
        "def play_games(player_x, player_o, rounds=50):\n",
        "    wins = losses = draws = 0\n",
        "    for _ in range(rounds):\n",
        "        game = Game(player_x, player_o)\n",
        "        game.show_board = False\n",
        "        game.play()\n",
        "        if game.winner == player_x.symbol:\n",
        "            wins += 1\n",
        "        elif game.winner == player_o.symbol:\n",
        "            losses += 1\n",
        "        else:\n",
        "            draws += 1\n",
        "    return wins, losses, draws\n",
        "\n",
        "# Game 0: RandomAgent \"O\" vs. ValueIterationAgent \"X\"\n",
        "player_x = QLearningAgent(PLAYER_X)\n",
        "player_o = RandomAgent(PLAYER_O)\n",
        "player_x.train()\n",
        "wins0, losses0, draws0 = play_games(player_x, player_o)\n",
        "print(f\"Game 0: Wins: {wins0}, Losses: {losses0}, Draws: {draws0}\")\n",
        "\n",
        "# Game 1: RandomAgent \"X\" vs. ValueIterationAgent \"O\"\n",
        "player_x = QLearningAgent(PLAYER_X)\n",
        "player_o = AggressiveAgent(PLAYER_O)\n",
        "player_x.train()\n",
        "wins1, losses1, draws1 = play_games(player_x, player_o)\n",
        "print(f\"Game 1: Wins: {wins1}, Losses: {losses1}, Draws: {draws1}\")\n",
        "\n",
        "# Game 2: ValueIterationAgent \"X\" vs. AggressiveAgent \"O\"\n",
        "player_x = QLearningAgent(PLAYER_X)\n",
        "player_o = AggressiveAgent(PLAYER_O)\n",
        "player_x.train()\n",
        "wins2, losses2, draws2 = play_games(player_x, player_o)\n",
        "print(f\"Game 2: Wins: {wins2}, Losses: {losses2}, Draws: {draws2}\")\n",
        "\n",
        "# Game 3: ValueIterationAgent \"O\" vs. AggressiveAgent \"X\"\n",
        "player_x = AggressiveAgent(PLAYER_X)\n",
        "player_o = QLearningAgent(PLAYER_O)\n",
        "player_o.train()\n",
        "wins3, losses3, draws3 = play_games(player_x, player_o)\n",
        "print(f\"Game 3: Wins: {wins3}, Losses: {losses3}, Draws: {draws3}\")\n",
        "\n",
        "# Game 4: ValueIterationAgent \"X\" vs. DefensiveAgent \"O\"\n",
        "player_x = QLearningAgent(PLAYER_X)\n",
        "player_o = DefensiveAgent(PLAYER_O)\n",
        "player_x.train()\n",
        "wins4, losses4, draws4 = play_games(player_x, player_o)\n",
        "print(f\"Game 4: Wins: {wins4}, Losses: {losses4}, Draws: {draws4}\")\n",
        "\n",
        "# Game 5: ValueIterationAgent \"O\" vs. DefensiveAgent \"X\"\n",
        "player_x = DefensiveAgent(PLAYER_X)\n",
        "player_o = QLearningAgent(PLAYER_O)\n",
        "player_o.train()\n",
        "wins5, losses5, draws5 = play_games(player_x, player_o)\n",
        "print(f\"Game 5: Wins: {wins5}, Losses: {losses5}, Draws: {draws5}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
